{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "\n",
    "# three customized modules\n",
    "from labelshift import *\n",
    "from utils4gluon import *\n",
    "from data_shift import *\n",
    "from data import *\n",
    "\n",
    "np.random.seed(112358)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'cifar10' # choices: 'mnist', 'cifar10'\n",
    "\n",
    "################################################\n",
    "# Decide whether to tweak the training dist and how\n",
    "################################################\n",
    "tweak_train = True # options include \n",
    "\n",
    "# UNCOMMENT to MANUALLY set training label distribution\n",
    "p_P = [.1, .1, .1, .1 ,.1 ,.1, .1, .1, .1, .1]\n",
    "\n",
    "# UNCOMMMENT to sample label distribution from Dirchlet w\n",
    "# alpha = 1.\n",
    "# p_P = np.random.dirichlet([1.]*10)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Decide whether to tweak the test dist and how\n",
    "################################################\n",
    "tweak_test = True\n",
    "\n",
    "# UNCOMMENT to MANUALLY set training label distribution\n",
    "# p_Q = [.91, .01, .01, .01 ,.01 ,.01, .01, .01, .01, .01]\n",
    "\n",
    "# UNCOMMENT to sample label distribution from Dirchlet w\n",
    "alpha = .01\n",
    "p_Q = np.random.dirichlet([1.]*10)\n",
    "\n",
    "num_train_samples = 30000\n",
    "num_val_samples = 30000\n",
    "num_test_samples = 10000\n",
    "\n",
    "################################################\n",
    "# Neural network configurations\n",
    "################################################\n",
    "num_hidden = 256\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling training and validation data from p_P\n",
      "Current p_P:  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "Sampling test data from p_Q\n",
      "Current p_Q:  [ 0.05192518  0.403422    0.0252058   0.00061585  0.15051928  0.05287386\n",
      "  0.23776149  0.0213737   0.00853258  0.04777026]\n"
     ]
    }
   ],
   "source": [
    "# set the context\n",
    "ctx = mx.gpu()\n",
    "\n",
    "# load the dataset\n",
    "X, y, Xtest, ytest = load_data(dataset_name)\n",
    "    \n",
    "batch_size = 64\n",
    "n = X.shape[0]\n",
    "dfeat = np.prod(X.shape[1:])\n",
    "\n",
    "# NOTE FOR IMPROVEMENT: eventually this should be returned by the data library\n",
    "num_labels = 10\n",
    "\n",
    "################################################\n",
    "# Random permutation of the data\n",
    "################################################\n",
    "\n",
    "rand_idx = np.random.permutation(n)\n",
    "X = X[rand_idx,...]\n",
    "y = y[rand_idx]\n",
    "\n",
    "################################################\n",
    "#  First split examples between train and validation\n",
    "################################################\n",
    "num = 2  \n",
    "Xtrain_source = X[:(n//num),:,:,:]\n",
    "ytrain_source = y[:(n//num)]\n",
    "Xval_source = X[(n//num):(2*n//num),:,:,:]\n",
    "yval_source = y[(n//num):(2*n//num):]\n",
    "\n",
    "\n",
    "################################################\n",
    "#  Set the label distribution at train time\n",
    "################################################\n",
    "if tweak_train:\n",
    "    print(\"Sampling training and validation data from p_P\")\n",
    "    print(\"Current p_P: \", p_P)\n",
    "\n",
    "    Xtrain, ytrain = tweak_dist(Xtrain_source, ytrain_source, num_labels, num_train_samples, p_P)\n",
    "    Xval, yval = tweak_dist(Xval_source, yval_source, num_labels, num_val_samples, p_P)\n",
    "else:\n",
    "    Xtrain, ytrain = Xtrain_source, ytrain_source\n",
    "    Xval, yval = Xval_source, yval_source\n",
    "\n",
    "################################################\n",
    "#  Set the label distribution for test data\n",
    "################################################\n",
    "if tweak_test:\n",
    "    print(\"Sampling test data from p_Q\")\n",
    "    print(\"Current p_Q: \", p_Q)\n",
    "    Xtest, ytest = tweak_dist(Xtest, ytest, num_labels, num_test_samples, p_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3, 32, 32)\n",
      "(30000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.1023      0.1011      0.09733333  0.09956667  0.10146666  0.10123333\n",
      "  0.10076667  0.1002      0.10016666  0.09586667]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[ 0.09883333  0.09903333  0.09916667  0.10156666  0.1012      0.09963334\n",
      "  0.10003334  0.0995      0.09936666  0.10166667]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[ 0.0534  0.4064  0.0269  0.0005  0.148   0.0542  0.2343  0.0227  0.0072\n",
      "  0.0464]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# debugging code\n",
    "print(nd.one_hot(nd.array(ytrain), 10).sum(axis=0) / len(ytrain))\n",
    "print(nd.one_hot(nd.array(yval), 10).sum(axis=0) / len(yval))\n",
    "print(nd.one_hot(nd.array(ytest), 10).sum(axis=0) / len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 1.87659304347, Train_acc 0.339885394456, Validation_acc 0.329257729211\n",
      "Epoch 1. Loss: 1.72369736903, Train_acc 0.389692164179, Validation_acc 0.371735074627\n",
      "Epoch 2. Loss: 1.6248598581, Train_acc 0.419542910448, Validation_acc 0.392390724947\n",
      "Epoch 3. Loss: 1.54958461123, Train_acc 0.438699360341, Validation_acc 0.404750799574\n",
      "Epoch 4. Loss: 1.48154066063, Train_acc 0.469049840085, Validation_acc 0.412646588486\n"
     ]
    }
   ],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_labels))\n",
    "\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})\n",
    "\n",
    "# Training\n",
    "\n",
    "\n",
    "# Prediction\n",
    "ypred_s, ypred_s_soft = predict_all(Xval, net, ctx, dfeat)\n",
    "ypred_t, ypred_t_soft = predict_all(Xtest, net, ctx, dfeat)\n",
    "\n",
    "\n",
    "# Converting to numpy array for later convenience\n",
    "ypred_s= ypred_s.asnumpy()\n",
    "ypred_s_soft = ypred_s_soft.asnumpy()\n",
    "ypred_t=ypred_t.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Wt and Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61568333  0.54030354]\n",
      " [ 4.11867255  4.1036688 ]\n",
      " [ 0.78713783  0.2712605 ]\n",
      " [ 0.17984028  0.00492287]\n",
      " [ 1.32314199  1.46245059]\n",
      " [ 0.0796509   0.54399465]\n",
      " [ 2.28978031  2.34221926]\n",
      " [ 0.11646368  0.2281407 ]\n",
      " [ 0.17112826  0.07245891]\n",
      " [ 0.34874449  0.45639344]]\n",
      "[[ 0.06085004  0.0534    ]\n",
      " [ 0.40788587  0.4064    ]\n",
      " [ 0.07805784  0.0269    ]\n",
      " [ 0.01826578  0.0005    ]\n",
      " [ 0.13390197  0.148     ]\n",
      " [ 0.00793588  0.0542    ]\n",
      " [ 0.22905436  0.2343    ]\n",
      " [ 0.01158814  0.0227    ]\n",
      " [ 0.01700444  0.0072    ]\n",
      " [ 0.03545569  0.0464    ]]\n",
      "||wt - wt_true||^2  = 0.022613514546137293\n",
      "KL(Py_est|| Py_true) = array([ 0.61273163])\n"
     ]
    }
   ],
   "source": [
    "wt = estimate_labelshift_ratio(yval, ypred_s, ypred_t,num_labels)\n",
    "\n",
    "Py_est = estimate_target_dist(wt, yval,num_labels)\n",
    "\n",
    "Py_true =calculate_marginal(ytest,num_labels)\n",
    "Py_base =calculate_marginal(yval,num_labels)\n",
    "\n",
    "wt_true = Py_true/Py_base\n",
    "\n",
    "print(np.concatenate((wt,wt_true),axis=1))\n",
    "print(np.concatenate((Py_est,Py_true),axis=1))\n",
    "\n",
    "print(\"||wt - wt_true||^2  = \" + repr(np.sum((wt-wt_true)**2)/np.linalg.norm(wt_true)**2))\n",
    "print(\"KL(Py_est|| Py_true) = \" + repr(stats.entropy(Py_est,Py_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve weighted ERM and compare to previously trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy unweighted 0.403761942675\n",
      "Epoch 0. Loss: 1.41994833343, Train_acc 0.219549573561, Validation_acc 0.210920842217\n",
      "Epoch 1. Loss: 1.27097178876, Train_acc 0.250732942431, Validation_acc 0.238506130064\n",
      "Epoch 2. Loss: 1.18565286155, Train_acc 0.267157515991, Validation_acc 0.25006663113\n",
      "Epoch 3. Loss: 1.11673102186, Train_acc 0.261293976546, Validation_acc 0.246501865672\n",
      "Epoch 4. Loss: 1.06252223125, Train_acc 0.28158315565, Validation_acc 0.26012793177\n",
      "Accuracy weighted 0.587878184713\n"
     ]
    }
   ],
   "source": [
    "data_test = mx.io.NDArrayIter(Xtest, ytest, batch_size, shuffle=False)\n",
    "\n",
    "acc_unweighted =  evaluate_accuracy(data_test, net, ctx, dfeat) # in fact, drawing confusion matrix maybe more informative\n",
    "\n",
    "print(\"Accuracy unweighted\", acc_unweighted)\n",
    "\n",
    "training_weights=np.maximum(wt, 0)\n",
    "wt_ndarray = nd.array(training_weights,ctx=ctx)\n",
    "\n",
    "\n",
    "weightfunc = lambda x,y: wt_ndarray[y.asnumpy().astype(int)]\n",
    "\n",
    "# Train a model using the following!\n",
    "net2 = gluon.nn.Sequential()\n",
    "with net2.name_scope():\n",
    "    net2.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net2.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net2.add(gluon.nn.Dense(num_labels))\n",
    "\n",
    "net2.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "trainer2 = gluon.Trainer(net2.collect_params(), 'sgd', {'learning_rate': .1})\n",
    "epochs2 = 5\n",
    "\n",
    "# Training\n",
    "weighted_train(net2, softmax_cross_entropy, trainer2, Xtrain, ytrain, Xval, yval, ctx, dfeat, epoch=epochs2, weightfunc=weightfunc)\n",
    "\n",
    "data_test.reset()\n",
    "acc_weighted = evaluate_accuracy(data_test, net2, ctx, dfeat)\n",
    "\n",
    "print(\"Accuracy weighted\", acc_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
